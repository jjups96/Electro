{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si alguna vez has usado la regresión lineal, has usado una de las formas más simples y fácilmente interpretables del aprendizaje supervisado (supervised learning), una serie de técnicas enmarcadas dentro del amplio campo del aprendizaje automático (machine learning), tan de moda últimamente.\n",
    "\n",
    "La regresión lineal se usa para hacer predicción de variables cuantitativas, principalmente, y, aunque pueda parecer una técnica simple, sigue estando vigente pues se puede aplicar de forma sencilla a multitud de problemas. Además, sirve como punto de entrada para definir técnicas más complejas y sofisticadas dentro del análisis de regresión.\n",
    "\n",
    "La siguiente libreta muetra lo mas básico de la regresión lineal simple, la obtención de la relación entre una variable predictora, X, y la variable cuantitativa que queremos obtener, Y, y su coeficiente de correlación.\n",
    "\n",
    "Como siempre, antes de nada importamos las librerías que usaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pimero lo primero\n",
    "El realizar una regresion lineal en python es facil si sabemos aprovechar las librerias, y se hace asi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(4,9,'Y = 0.500 X + 3.000')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd4VVXWx/HvJrRQQ1UgUgOhN0NRUWoojiBWGETKMBKKgKBRIiKMwwADKEVRQKS+jqBIsdI7SAlNikZ6SegQakLaev8ILbkJJLktOXd9nocHsu8p68T447DP3vsYEUEppVTWl83dBSillHIMDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLKI7K48WdGiRaVs2bKuPKVSSmV5O3bsuCAixR62nUsDvWzZsoSGhrrylEopleUZY46nZTvtclFKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYt4aKAbY2YYY84ZY/bd1/aKMWa/MSbBGBPg3BKVUkqlRVru0GcBrZO17QNeBNY7uiCllFIZ89BX0InIemNM2WRtfwAYY5xTlVJKqXTTPnSllLIIpwe6MaanMSbUGBN6/vx5Z59OKaU81kO7XOwlItOAaQABAQHi7PMppdxn8a5wxi4LIyIyipI+3gS38qd9nVLuLstjOD3QlVKeYfGucEIW7iUqNh6A8MgoQhbuBdBQd5G0DFv8BvgN8DfGnDLG9DDGvGCMOQU8AfxsjFnm7EKVUpnb2GVhd8P8jqjYeMYuC3NTRZ4nLaNc/p7KR4scXItSKguLiIxKV7tyPB3lopRyiJI+3ulqV46nga6UcojgVv545/BK0uadw4vgVv5uqsjz6ENRpZRD3HnwqaNc3EcDXSnlMO3rlNIAdyPtclFKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQFdKKYvQQE+HUaNG4efnh7+/P8uWpbzA5KpVq6hbty61a9emUaNGHDp0CID169dTt25dsmfPzoIFC5Lsc+LECVq2bEmVKlWoWrUqx44dc/alKKUsyGMCXURISEjI8P4HDhxg3rx57N+/n6VLl9KnTx/i4+Nttuvduzdff/01u3fvplOnTowYMQKA0qVLM2vWLDp16mSzT5cuXQgODuaPP/5g27ZtFC9ePMN1KqU8l6UD/dixY1SpUoU+ffpQt25dTp48meFjLVmyhI4dO5IrVy7KlSuHn58f27Zts9nOGMPVq1cBuHLlCiVLlgSgbNmy1KxZk2zZkn7LDxw4QFxcHIGBgQDky5ePPHnyZLhOpZTnsvxaLmFhYcycOZPPP//c5rOBAweyZs0am/aOHTsyePDgJG3h4eE0bNjw7te+vr6Eh4fb7Dt9+nSeffZZvL29KVCgAFu2bHlgfX/99Rc+Pj68+OKLHD16lBYtWjB69Gi8vLweuJ9SSiX30EA3xswAngPOiUj1222FgflAWeAY8KqIXHZemRlXpkyZJEF8v/Hjx6f5OCK2r0M1xqR4zF9++YUGDRowduxYBg0axPTp01M9blxcHBs2bGDXrl2ULl2aDh06MGvWLHr06JHm2pRSCtLW5TILaJ2sbTCwSkQqAqtuf50p5c2bN9XPBg4cSO3atW1+jR492mZbX1/fJF02p06dutudcsf58+fZs2cPDRo0AKBDhw5s3rz5gfX5+vpSp04dypcvT/bs2Wnfvj07d+5MzyUqpRSQtlfQrTfGlE3W/DzQ5PafZwNrgfccWJdLpOcOvV27dnTq1IlBgwYRERHBwYMHqV+/fpJtChUqxJUrV/jrr7+oVKkSK1asoEqVKg88br169bh8+TLnz5+nWLFirF69moCAgAxdj8o6EiSBbMbSj7AsafGu8Ey93ntGf6IeEZHTALd/t/ywjGrVqvHqq69StWpVWrduzeTJk+/2cz/77LNERESQPXt2vvzyS1566SVq1arF3LlzGTt2LADbt2/H19eX7777jqCgIKpVqwaAl5cX48aNo3nz5tSoUQMR4Y033nDbdSrn++nIT3Rf2p2bsTfdXYpKh8U7T3Fm0RA2Rb9A42y7CI+MImThXhbvsn2W5i4mpb5hm40S79B/uq8PPVJEfO77/LKIFEpl355AT4DSpUs/fvz4cQeUrVTWNPfAXMZsH0PAIwFMajaJ/Dnzu7sk9TCxUfBdN/hr6d2mbjHBrE2oA0ApH282DW7m1BKMMTtE5KH/dM/oKJezxpgSInLaGFMCOJfahiIyDZgGEBAQ8PC/PZSyIBFhws4JzNg3gxalWzD6mdHk8srl7rLUg1w9DdNbwNVTd5t2JfjRNeY9rnLv2VxEZJQ7qktRRgP9B6ArMPr270scVpFSFhOXEMfwzcNZcngJr1R6hSENhuCVTYelZlrhO+DLZHfcdbvyzP62nLgSY7N5SR9vFxX2cGkZtvgNiQ9AixpjTgHDSAzyb40xPYATwCvOLFKprCoqLorgdcGsO7WO3rV607tW7xSHu6pMYO8C+D7ZcOE2Y6BBEACDHgsnZOFeomLvzRD3zuFFcCt/V1b5QGkZ5fL3VD5q7uBalLKUK7eu0G91P3af280HDT6gQ+UO7i5JJScCqz6CjZ8kbX99MVRomqTpzmiWzDzKxfIzRZVyhzM3ztB7ZW+OXz3OuMbjaFm2pbtLUveLjYJvu8LB+xbZy+4NvTdBkQqp7ta+TqlMFeDJaaAr5WBHIo8QtDKIazHX+KLFFzQo0cDdJak7rp6G6c3h6n1DDX3rQefvIXdB99XlIBroSjnQ7+d/p8+qPmQ32ZnZaiZVijx4YplykVM7YHqyB52Pd4e/fQwWekCtga6Ug2w4tYG3171NkdxFmBY4jccKPObuktTv38HCfyZte3Yc1Lfm5D0NdKUc4MfDP/Lhpg+pWKgin7f4nKLeRd1dkucSgZXDYdOEpO1dfoDyjd1SkqtooCtlp9n7ZzMudBwNHm3AhKYTyJczn7tL8kwxN+HbLnBoxb22HHmh14YHPui0Eg10pTJIRBi/Yzwz988ksEwgo58eTU6vnO4uy/NcPgZftYLrZ+61PdYAXvvOEg8600MDXakMiE2IZfjm4fxw+Ac6+HcgpH6Izv50tS1TYGmyRV4DesCzYy31oDM9NNCVSqebsTd5Z907bAjfQJ/afehVs5fO/nSl/3s5abcKQO3O0H6ye+rJRDTQlUqHyOhI+q7uy74L+xjacCiv+r/q7pI8Q0ICfJTCgq6N34Om77u+nkxKA12pNDpz4wxBK4I4ee0kHzf+mBZlWri7JOu7cRHGlrdtf30RVHDukrVZkQa6UmlwJPIIPVf05EbsDaYGTqXeo/XcXZK1ndwOX6XwF+bAA1Aw8069dzcNdKUeYve53by5+s3E2Z+tZ1K5cGV3l2Rdv30Oy0Js24deAK8crq8ni7H0Sw1FhEaNGvHrr7/ebfv2229p3Tr5O6/Td8z+/fvj5+dHzZo1U32hc5MmTfD397/74ulz5xLfAXLr1i06dOiAn58fDRo04NixY3f3GTVqFH5+fvj7+7Ns2TKbY167do0KFSpw8OBBAGJjY6lRowZbt27N8PUALFmyhJo1a1K7dm0CAgLYuHFjitvt2LGDGjVq4OfnR//+/bnztqtLly4RGBhIxYoVCQwM5PLly0Dav1eZ2fpT63lj+RsUyFmAuc/O1TB3ljntYXjBpGH+aE0YfiXxl4Z52oiIy349/vjj4mp79+6VypUrS1RUlFy/fl38/Pzk0KFDGT7ezz//LK1bt5aEhAT57bffpH79+ilu17hxY9m+fbtN++TJkyUoKEhERL755ht59dVXRURk//79UrNmTYmOjpYjR45I+fLlJS4uzmb/+fPnS2BgoIiIjBw5Unr27PnAeo8ePSqNGzd+4DbXrl2ThIQEERHZs2eP+Pv7p7hdvXr1ZPPmzZKQkCCtW7eWX375RUREgoODZdSoUSIiMmrUKHn33XdFJO3fq8xqyaElUmt2LXnlh1fk/M3z7i7HeuLjRIYVsP21ZpS7K8t0gFBJQ8Za+g4doHr16rRt25b//ve//Otf/6JLly5UqJDxWWNLliyhS5cuGGNo2LAhkZGRnD59Ol37d+3aFYCXX36ZVatWISIsWbKEjh07kitXLsqVK4efnx/btm2z2f/VV18lW7ZsjBkzhilTpjBq1KgMX8sd+fLluzvs7saNGykOwTt9+jRXr17liSeewBhDly5dWLx4sc01de3aNUm7Pd8rd5q5byZDNg4h4NEAZrSaoVP5HenGhcS78Y8KJ23vsiTxbrzJYPfUZQEe0Yc+bNgw6tatS86cOQkNDbX5vEOHDoSFhdm0Dxo0iC5duiRpCw8P57HH7i265OvrS3h4OCVKlLDZv3v37nh5efHSSy/xwQcfYIxJsn/27NkpWLAgFy9eJDw8nIYNG9ocNyUTJkygSpUqTJs2jcKFC6e4TXotWrSIkJAQzp07x88//2zzeXh4OL6+vinWd/bs2bvXX6JEibvdS+n5XmUWCZLAJ6GfMPvAbFqVbcXIRiN19qejnNgKM1JYF37QH1CgpOvrsSC7At0YMwB4AzDAlyIy4SG7uEXevHnp0KED+fLlI1cu2xfzzp8/P83HErF9z3VKd7Rff/01pUqV4tq1a7z00kvMnTuXLl26pLp/Wo8LsHTpUkqUKMG+fftSrfOFF17g6NGjxMTEcOLECWrXrg3AgAED6N69e4rbv/DCC6xfv56hQ4eycuXKJJ+npz579nGn2IRYhm0axo9HfuTvlf/O4PqDyWYs/49Y59v8GSwfYtuuDzodLsOBboypTmKY1wdigKXGmJ9F5KCjinOkbNmykS1byv9zpucO3dfXl5MnT979+tSpU5QsaXt3UapU4tCq/Pnz06lTJ7Zt20aXLl3u7u/r60tcXBxXrlyhcOHCaT5uREQEkyZNYtu2bTRt2pQePXpQs2ZNm+0WLVoEwLFjx+jWrRtr165N8dqTe+aZZzh8+DAXLlygaNF73Qy+vr6cOnXv7ef31/fII49w+vRpSpQowenTpylevHi6vleZwc3Ym7y97m02hm/kzdpv0rNmz0z9l0+WMLstHF2ftK1kXei5xj31eAB7bj+qAFtE5KaIxAHrgBccU5ZrzZ8/n927d9v8Sh7mAO3atWPOnDmICFu2bKFgwYI2XQhxcXFcuHABSByJ8tNPP1G9evW7+8+ePRuABQsW0KxZM4wxtGvXjnnz5nHr1i2OHj3KwYMHqV+/vs35Bw4cyPvvv4+vry+ffPIJffv2TfFOOD0OHTp09xg7d+4kJiaGIkWKJNmmRIkS5M+fny1btiAizJkzh+eff97mmmbPnp2k/WHfq8wgMjqSN5a/weaIzQx7YhhBtYI0zDMqPi6xf3x4waRh3nRIYv+4hrlzpeXJaUq/SAz0v4AiQB7gN+DTFLbrCYQCoaVLl3bWQ+CHGjZsmIwdO9bu4yQkJEifPn2kfPnyUr169SQjWWrVqiUiItevX5e6detKjRo1pGrVqtK/f/+7I1aioqLk5ZdflgoVKki9evXk8OHDd/cfMWKElC9fXipVqnR3BMn9li9fLg0bNrw7IkVEpG3btjJr1qxU603LKJfRo0dL1apVpVatWtKwYUPZsGGDzTWJiGzfvl2qVasm5cuXl759+96t48KFC9KsWTPx8/OTZs2aycWLFx/6vcosIq5FSNtFbaXunLqy8thKd5eTdV06lvKIlSPr3F2ZJZDGUS5G7Li7M8b0APoC14EDQJSIDExt+4CAAEnpoaRS7nDo8iGCVgYRFRvFpGaTCHg0wN0lZT17F8D3PWzb39wBRf1cX49FGWN2iMhDf0DteigqIl8BX90+4Ujg1IP3UCpz2H1uN31X9SUhwQs53ZtXJpylpM9qglv5Z+q3umca8zvDHz/atn9wHrLrqCB3sXeUS3EROWeMKQ28CDzhmLKUcp51J9fxzrp3yOtVhLOHuhAVlfgShPDIKEIW7gXQUE/N8FReGDH8imvrUCmydxz698aYIkAs0FdELjugJqWcZvGhxQzfPBz/wv6cONCJqKik/wtExcYzdlmYBvr94mPh3ylMrPILhM4LXF+PSpW9XS5PO6oQpZxJRJixbwYTdk6gYYmGTGg6geob16a4bURklGuLy6wuHYVJtW3b20+B2n93fT3qoTxipqjybAmSwLjQccw9MJc2Zdvwn0b/IYdXDkr6eBOeQniX9PF2Q5WZyJ75sKinbXu/nR7zsuWsSgNdWVpsfCwfbPqAX47+QqfKnXiv/nt3Z38Gt/InZOFeomLj727vncOL4Fb+7irXvb75O4T9YtuuMzqzDA10ZVk3Y28yaO0gNkVsYkDdAfSo3iPJhKE7/eRjl4URERlFSR9vzxzlog86LUMDXVnS5ejL9F3Vl/0X9/OvJ//FixVfTHG79nVKeV6AQ+oPOiu1gU7zXF+PcggNdGU5EdcjCFoRxOkbpxnfZDzNSuu7J++6dAQm1bFtf2Ea1Org+nqUQ2mgK0s5ePkgvVb0IiouiqmBU3n8kcfdXVLmsPsbWNzLtr3/bihczvX1KKfQQFeWsfPsTt5c/Sa5vXIzq80sKhWq5O6S3O/rV+Dgctt2fdBpSRroyhLWnFhD8PpgSuQtwZTAKZTK54H94vfTB50eSVfvV1neooOLeGvtW1T0qcjsNrM9N8zjYu4tXXufddkaUC76fzyVexGLd6X8FixlDXqHrrIsEeGrfV8xcedEniz5JOObjCdPjjzuLsv1Lh6GT+vaNIc+PobXt5UhKjpxnL2uVWN9eoeusqQESWDM9jFM3DmRNuXa8FmzzzwvzHd9nXg3njzMB+yB4VcYsL9ikklTcG+tGmVNeoeuspzY+FiGbBrCr0d/pXOVzgTXC/asd3/OfREOr7JtH3oRvO79L53amjS6Vo11aaCrLOVG7A0GrhnIb6d/S3H2p6Wl80GnrlXjeTTQVZZxKfoSfVb24c9Lf/LRkx/xQsUs+Qrb9ImLgRHFbNurPg+vznngrrpWjefRQFdZQvj1cIJWBHHmxhkmNJ1Ak8eauLsk57pwED5L4Y1jL8+A6i+l6RC6Vo3n0UBXmV7YpTB6r+xNdHw0X7b8kjrFU5i6bhU758AP/Wzb39oLPqXTfTiPXavGQ9n7CrqBwD8BAfYC3UUk2hGFKQWw4+wO+q3qh3d2b2a3nk3FQhXdXZJdFu8KT/mOeXZbOLredodkDzqVepAM/6QYY0oB/YGqIhJljPkW6AjMclBtysOtOrGKd9e9S8l8JZkaOJWS+Uq6uyS7LN4VnqRPOzwyivZLqsKSFDbWGZ0qA+z9qz874G2MiQXyABH2l6QUfP/X93y05SOqFanG5OaTKZS7kLtLstvYZWFExcaTixjCcnez3aD6S4l95EplUIYDXUTCjTHjgBNAFLBcRFJYBUiptBMRvtz7JZ/u+pSnSj3FJ40/scyEoYJX/mRT7hCb9r4x/Zk88t9uqEhZjT1dLoWA54FyQCTwnTGms4j8X7LtegI9AUqXTv9DHeU5EiSB0dtG882f3/Bc+ef46KmPyJHNAisCbhwPK4fzS66kzc/cGs8JeYRSOi5cOYg9XS4tgKMich7AGLMQeBJIEugiMg2YBhAQECB2nE9ZWEx8DEM2DmHpsaV0qdqFtwPezvqzPyfUgMgTNs0VoucSjxeg48KVY9kT6CeAhsaYPCR2uTQHQh1SlfIoN2Jv8Naat9hyeguDHh9E9+rd3V2SfR4wo3PxrnAe1XHhykns6UPfaoxZAOwE4oBd3L4TVyqtLkZdpM+qPoRdCuPfT/2b9n7t3V1SxsRGwX8etW0v0wi6/3z3Sx0XrpzJrlEuIjIMGOagWpSHOXXtFEErgjh38xwTm06k8WON3V1S+p3eA1OfsW1//nOo85rr61EeTWcsKLcIuxRGr5W9iImP4cuWX1K7eG13l5Q+68fB6hRGpgzYA4XKurwcpUADXbnB9jPb6b+6P3lz5GVOmzlU8Kng7pLS7pOqcDWFt/58eAmyebm+HqXuo4GuXGrV8VW8u/5dfPP7MjVwKo/mTaHfOTPSd3RmSqkupeChNNCVy3z313eM2DKC6kWrM7nZZHxy+7i7pAeLuQkjS9i2l2sMXX9wfT0qiZSWUvD0V+xpoCunExGm/j6Vybsn06hUIz5u/HHmnv0ZsQumNbFtf2Eq1Oro8nJUyu4spXC/O6/Y00BXygniE+IZvW0088Lm0bZ8W/711L8y7+zPdWNgzX9s2zO4dK1yLn3Fni0NdOU0MfExhGwIYfnx5XSr1o2Bjw/MnLM/570Gf/5k264POjM1fcWeLQ105RTXY67z1pq32HpmK28//jbdqndzd0m29EFnlqav2LOlga4c7kLUBfqs7MPBywcZ2WgkbSu0dXdJ98RGw38esW1/+h1oPtT19agM01fs2dJAVw518tpJglYEcf7meSY1m8TTvk+7u6REFw/Dp3Vt27v+BOUySY0q3XQphaQ00JXD/HnpT3qt6EWcxDG91XRqFavl7pLg929h4Ru27cGHIW9R19ejlBNpoGdBmXEyxbbT2+i/pj/5c+ZnRosZlPcp79Z6+K4b7F9k2/7hZciWCR/MKuUAGuhZTGacTLH82HIGbxhM6fylmRI4xb2zP1N60FnED/rtcH0tSrmYBnoWk9kmU3wb9i0jtoygVrFafNb8MwrmSmXkiDOl9qCz8XvQ9H3X16OUm2igZzGZZTKFiDBlzxQ+3/M5z/g+w7jG4/DO7uLxvxcOwmcBtu3dfoayjVxbi1KZgAZ6FpMZJlPEJ8Qzatso5ofNp12Fdgx/crhrZ3/u/gYW97JtDz4CeYu4rg6lMhl7XhLtD8y/r6k88KGITLC7KpUqd0+muBV/i5ANIaw4voLu1bszsO5AjDEuOTffdoEDS2zb9UGnUoB9r6ALA2oDGGO8gHAghWEFypHcOZniWsw1BqwZwPYz23kn4B26Vuvq9HMCKT/oLFoJ3tzumvMrlUU4qsulOXBYRI476HjqAdwxmeJC1AV6r+zNocuHnDr7886QzIuRV/gzdzfbDZq8D03ec8q5lcrqHBXoHYFvHHQslcmcvHqSnit6cjH6Ip82/5RGpZzzwHHxrnA+WbieTV69IHeyD7v/CmWedMp5lbIKuwPdGJMTaAeEpPJ5T6AnQOnSugRpVvPHxT/otbIXCZLA9JbTqVmspnNOdGIr7Ze0pH2yxQ1rR08lr09xNmmYK/VQjrhDbwPsFJGzKX0oItOAaQABAQHigPMpF9l6eisD1gwgf878TA2cSvmCTpj9ue1L+OWdJE1bEqrQMeYDIPFh6xUPXt9aqfRwRKD/He1usZxlx5YRsiGEMgXK8EWLLxw/+3PBP2Df90mapmfvyIjr7Ww29eT1rZVKD7sC3RiTBwgEghxTjsoM5v05j5FbR1K7eG0+bfap42Z/xsXAuIoQHZm0vdN3UKklRXeF463rWyuVYXYFuojcBHQmh0WICJN3T2bq71Np4tuEMY3HOGb259XT8Ell2/Z+O6FIhbtf6vrWStlHZ4oqIHH254itI1jw1wJe8HuBD5/4kOzZ7PzxOLEFZrSybX8/AnLmTXEXXd9aqYzTQFfcir/F4PWDWXliJT2q92BA3QH2zf5M4UEnZZ+Grj+Cq2aVKuWBNNA93LWYa/Rf3Z/Qs6G8W+9dXq/6esYPltIa5E2HQON37apRKZU2Guge7PzN8/Re2ZvDkYcZ/fRo/lb+b+k/SFwMjPWDW8lerPzaAqgY6JhClVJpooHuoY5fPU7QiiAuRV9icvPJPFkqnRN3rkbAJ1Vs2/vvhsLlHFOkUipdNNA90P6L++mzsg8iwlctv6JGsRpp3/n4ZpjZxrb9AQ86lVKuoYHuYX6L+I231ryFTy4fpgROoVzBNN5Nb50KvybrCy/fBF5frA86lcokNNA9yNJjSwnZEELZAmWZGjiV4nmKP3yn+a/DHz8kbWv2ATwT7JwilVIZpoHuIf73x/8YvW00dYrXYVKzSQ+e/Rl3C8ZUgJhrSds7fw9+LZxbqFIqwzTQLU5E+Gz3Z0z7fRpNHmvC2GfGkjt78rVpb7sSDuOr2rYP2AOFyjq1TqWU/TTQLSwuIY4RW0bw/cHvebHiiwxtODTl2Z/HNsKsFIYsvn8acuZxfqFKKYfQQLeo6Lho3lv/HqtPruaNGm/Qr04/29mfW76ApYOTtpVvCq8v0gedSmVBGugWdDXmKv1W9WPXuV0Mrj+Y16q8lnSDea/Bnz8lbWv+ITz9tuuKVEo5nAa6xZy7eY5eK3tx9MpR/vvMf2lT7vaY8dhoGFMOYm8m3aHzQvBr7vpClVIOp4FuIceuHKPXyl73Zn+WfPIBDzp/h0JlXF+kUsppNNAtYt+FffRZ2QeAma1mUu3aJRiebGii8YL3wyGHvgFIKSvSQLeAzRGbeWvNWxTOXZgpRZ+m7GfJ1mXxa5G4WJY+6FTK0ux9BZ0PMB2oDgjwDxH5zRGFqbT55cgvDNk0hPKSnS8ObKN4/H3f/hbDodFAd5WmlHIxe+/QJwJLReRlY0xOQActu9DX+2YxesfHPB4VzaRz5ymQIIkfvL4YKjR1b3FKKZfLcKAbYwoAzwDdAEQkBohxTFnqQeTyCT6d04gvfQrS7MZNxpy/QC5BH3Qq5eHsuUMvD5wHZhpjagE7gAEicuP+jYwxPYGeAKVLl7bjdIqj64mb3ZZ/Fy3MQp+CvHT1Oh9cvkb298/og06lFEZEMrajMQHAFuApEdlqjJkIXBWRoantExAQIKGhoRmr1JNtmgQrhhJtDMHFirA2bx6CTBH6dl6NyZbN3dUppZzMGLNDRAIetp09d+ingFMisvX21wuAwQ/YXqWHCPyvAxxcBsCVbIb+jxRjV+7chNQPoVOVTm4uUCmV2WQ40EXkjDHmpDHGX0TCgObAAceV5qFio2GULyTE3m066+VFr8oBHIs+z5inR9G6bGs3FqiUyqzsHeXSD/j69giXI0B3+0vyUJEnYILtq+CO9lhK0NZhXLlbAkW7AAAMcUlEQVR1hS9afEHDEg3dUJxSKiuwK9BFZDfw0H4dq1u8K5yxy8KIiIyipI83wa38aV+nVNp2PrIW5jyftM0rFww+wd7Ig/RZ1YdsJhszWs+gWpFqDq9dKWUdOlPUTot3hROycC9RsfEAhEdGEbJwL8CDQ33jBFg5LGlbpTbw92/AGDaFb2Lg2oEUzl2YqYFTKVNAhyMqpR5MA91OY5eF3Q3zO6Ji4xm7LMw20EXg65fh0Mqk7S1HwJP97n7505GfGLpxKBV8KvBFiy8olqeYs8pXSlmIBrqdIiKjHt4eGwUjS4IkJN2o649Q7pkkTXMPzGXM9jEEPBLApGaTyJ8zv6NLVkpZlAa6nUr6eBOeQqiX9PGGy8dhYk3bnQbuh4K+SZpEhAk7JzBj3wxalG7B6GdGk8srl7PKVkpZkM5KsVNwK3+8c3glaWueYz+bol9IGubZvWHIWRh+xSbM4xLi+HDzh8zYN4NXKr3CuMbjNMyVUummd+h2utNPPnZZGO2uzee9HPOSblD5Oej4dar7R8VFEbwumHWn1tG7Vm961+pt++5PpZRKAw10e4nQ/uxk2kdPhhz3tbcaCU/0feCuV25dod/qfuw+t5shDYbQsXJH59aqlLI0DfSMirsFC3vCgcVJ27v9DGUbPXT3MzfO0Htlb45fPc64xuNoWbalkwpVSnkKDfT0un4eZrSCS4fvtT1SA7r+AHkKp+kQRyKPELQyiGsx1/iixRc0KNHAScUqpTyJBnpandkLU5LdedfsCM9/Bl45Ut4nBb+f/50+q/qQ3WRnZquZVClSxcGFKqU8lQb6w/zxI8zvnLQt2USgtNoYvpFBawdRJHcRpgVO47ECjzmoSKWU0kBPmQisGwNrRyZt7/QdVMpYX/ePh3/kw00f4lfIjy9afEFR76IOKFQppe7RQL9f3C34/p/wxw/3NRrouxWK+Wf4sLP3z2Zc6DjqP1qfiU0nki9nPvtrVUqpZDTQAa6fu/2g88i9tkdrQJe0P+hMiYgwfsd4Zu6fSWCZQEY9PUonDCmlnMazA/307zD16aRttTpBu0npetCZktiEWIZvHs4Ph3+gg38HQuqH4JXN6+E7KqVUBnlmoB9YAt92SdqWwQedKYmKi+Kdde+w/tR6+tTuQ6+avXT2p1LK6ewKdGPMMeAaEA/EpeUlpm4jAuv+C2tHJW1/7Xuo2MJhp7ly6wp9V/Vl74W9DG04lFf9X3XYsZVS6kEccYfeVEQuOOA4zhEbDd/3gD9/utdmvKDPFihWyaGnOnPjDEErgjh57SQfN/6YFmUc9xeFUko9jHW7XK6dhRkt4fKxe20lasHri+160JmaI5FH6LmiJzdibzA1cCr1Hq3n8HMopdSD2BvoAiw3xggwVUSmOaAmx5hYE+KiE/9cuzO0nQhezvn7a/e53by5+s3E2Z+tZ1K5cGWnnEcppR7E3oR7SkQijDHFgRXGmD9FZP39GxhjegI9AUqXLm3n6dKh289w5ncI+IdTT7P+1HreXvs2xfIUY2rgVB7Lr7M/lVLuYUTEMQcyZjhwXUTGpbZNQECAhIaGOuR8mcEPh3/gw00fUqlQJT5v8bllZ38u3hXO2GVhRERGUdLHm+BW/g9+AbZSyqGMMTvSMugkw28sMsbkNcbkv/NnoCWwL6PHy2pm7ZvFkI1DCHg0gBmtZlg6zEMW7iU8MgoBwiOjCFm4l8W7wt1dmlIqGXteQfcIsNEYswfYBvwsIksdU1bmlSAJjNs+jo93fEyrsq34vPnnlp7KP3ZZGFGx8UnaomLjGbsszE0VKaVSk+E+dBE5AtRyYC2ZXmxCLMM2DePHIz/S0b8jg+sPtvzsz4gUXoD9oHallPtYd9iig92Mvcnb695mY/hG3qz9Jj1r9vSI2Z8lfbwJTyG8S/p4u6EapdSD2NPl4jEioyN5Y/kbbI7YzLAnhhFUK8gjwhwguJU/3jmS/ivEO4cXwa0yvvqkUso59A79IU5fP03QyiDCr4XzSeNPaF6mubtLcqk7o1l0lItSmZ8G+gMcunyIXit7cTP2JlMDpxLwaOZdqsaZ2tcppQGuVBaggZ6K3ed203dVX3J65WRm65n4F9YuBqVU5qZ96ClYd3Idbyx/A59cPsxtM1fDXCmVJWigJ7P40GIGrBlAeZ/yzGkzB9/8vu4uSSml0kS7XG4TEWbsm8GEnRNoWKIhE5pOIG+OvO4uSyml0kwDnduzP0PHMffAXNqUbcN/Gv2HHHa+gk4ppVzN4wM9Nj6WoZuH8vORn+lUuRPv1X+PbEZ7opRSWY8lAz2tqwPejL3JoLWD2BSxif51+vPPGv/0mAlDSinrsVyg31kd8M6CUndWBwSShPrl6Mv0XdWX/Rf3M/yJ4bxU6SW31KuUUo5iub6FtKwOGHE9gi6/duGvy38xvsl4DXOllCVY7g79YasDHrx8kF4rehEVF8XUwKk8/sjjrixPKaWcxnJ36KmtAljSx5udZ3fSdWlXBGFWm1ka5kopS7FcoKe2OmDbJy7Tc0VPiuQuwtxn51KpUCU3VaiUUs5hd5eLMcYLCAXCReQ5+0uyT0qrAzard4x5xydRpXAVJreYTOHchd1cpVJKOZ4j+tAHAH8ABRxwLIe4szqgiPDVvq+YuHMiT5Z8kvFNxpMnRx53l6eUUk5hV5eLMcYX+Bsw3THlOE6CJDBm+xgm7pxIm3Jt+KzZZxrmSilLs/cOfQLwLpDfAbU4TGx8LEM2DeHXo7/SuUpngusF6+xPpZTlZTjljDHPAedEZMdDtutpjAk1xoSeP38+o6dLF0GIjI5kQN0BvFvvXQ1zpZRHMCKSsR2NGQW8DsQBuUnsQ18oIp1T2ycgIEBCQ0MzdL70ik+Ixyub18M3VEqpTM4Ys0NEHvrKtAzfuopIiIj4ikhZoCOw+kFh7moa5kopT6N9EUopZREOmfovImuBtY44llJKqYzRO3SllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLIIDXSllLKIDL+xKEMnM+Y8cNxlJ4SiwAUXns/VrHx9Vr420OvL6lx9fWVEpNjDNnJpoLuaMSY0La9tyqqsfH1WvjbQ68vqMuv1aZeLUkpZhAa6UkpZhNUDfZq7C3AyK1+fla8N9Pqyukx5fZbuQ1dKKU9i9Tt0pZTyGJYNdGOMlzFmlzHmJ3fX4mjGGB9jzAJjzJ/GmD+MMU+4uyZHMsYMNMbsN8bsM8Z8Y4zJ7e6a7GGMmWGMOWeM2XdfW2FjzApjzMHbvxdyZ432SOX6xt7++fzdGLPIGOPjzhrtkdL13ffZO8YYMcYUdUdtyVk20IEBwB/uLsJJJgJLRaQyUAsLXacxphTQHwgQkeqAF9DRvVXZbRbQOlnbYGCViFQEVt3+Oquahe31rQCqi0hN4C8gxNVFOdAsbK8PY8xjQCBwwtUFpcaSgW6M8QX+Bkx3dy2OZowpADwDfAUgIjEiEuneqhwuO+BtjMkO5AEi3FyPXURkPXApWfPzwOzbf54NtHdpUQ6U0vWJyHIRibv95RbA1+WFOUgq//0AxgPvApnmQaQlAx2YQOI3OsHdhThBeeA8MPN2l9J0Y0xedxflKCISDowj8a7nNHBFRJa7tyqneERETgPc/r24m+txpn8Av7q7CEcyxrQDwkVkj7truZ/lAt0Y8xxwTkR2uLsWJ8kO1AW+EJE6wA2y9j/Xk7jdl/w8UA4oCeQ1xnR2b1Uqo4wxQ4A44Gt31+Ioxpg8wBDgQ3fXkpzlAh14CmhnjDkGzAOaGWP+z70lOdQp4JSIbL399QISA94qWgBHReS8iMQCC4En3VyTM5w1xpQAuP37OTfX43DGmK7Ac8BrYq3x0RVIvOHYcztnfIGdxphH3VoVFgx0EQkREV8RKUviw7TVImKZOzwROQOcNMb4325qDhxwY0mOdgJoaIzJY4wxJF6fZR763ucHoOvtP3cFlrixFoczxrQG3gPaichNd9fjSCKyV0SKi0jZ2zlzCqh7+/9Nt7JcoHuIfsDXxpjfgdrASDfX4zC3/+WxANgJ7CXxZzRTzspLK2PMN8BvgL8x5pQxpgcwGgg0xhwkcaTEaHfWaI9Uru8zID+wwhiz2xgzxa1F2iGV68uUdKaoUkpZhN6hK6WURWigK6WURWigK6WURWigK6WURWigK6WURWigK6WURWigK6WURWigK6WURfw/eSDnPt/lUsUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17da78950b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X e Y serán el primer conjunto del cuarteto de Anscombe \n",
    "# (https://en.wikipedia.org/wiki/Anscombe%27s_quartet)\n",
    "X = np.array([10.0, 8.0,  13.0, 9.0,  11.0, 14.0, 6.0,  4.0,  12.0,  7.0,  5.0])\n",
    "Y = np.array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
    "\n",
    "#Identidad\n",
    "Lx =  np.array([4, 10])\n",
    "Ly =  np.array([4, 10])\n",
    "\n",
    "# Calculamos los coeficientes del ajuste (a X + b)\n",
    "a, b = np.polyfit(X, Y, 1)\n",
    "# Calculamos el coeficiente de correlación\n",
    "r = np.corrcoef(X, Y)\n",
    "\n",
    "# Dibujamos los datos para poder visualizarlos y ver si sería lógico \n",
    "# considerar el ajuste usando un modelo lineal\n",
    "plt.plot(X, Y, 'o')\n",
    "plt.xlim(np.min(X) -1, np.max(X) +1)\n",
    "plt.ylim(np.min(Y) -1, np.max(Y) +1)\n",
    "plt.plot(X, a * X + b)\n",
    "#identidad\n",
    "plt.plot( Lx,Ly )\n",
    "#Etiqueta\n",
    "plt.text(4, 10, 'r = {0:2.3f}'.format(r[0,1]))\n",
    "plt.text(4, 9, 'Y = {0:2.3f} X + {1:2.3f}'.format(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion lineal simple, version un poco mas larga...\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya hemos comentado, con la regresion lineal simple lo que buscamos es la relacion entre un predictor, ***X***, y un predictando, ***Y***, asumiendo que la relacion entre ambas seria aproximadamente lineal. La relacion la podemos escribir asi:\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Y = a X + b$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $a$ y $b$ son dos constantes (coeficientes o parametros del modelo lineal) que definen, respectivamente, la pendiente y el termino independiente (u ordenada en el origen o intercepto). Una vez que conocemos $\\hat{a}$ y $\\hat{b}$ (\\*), obtenidos a partir de los datos de entrenamiento (conjunto de datos que usamos para obtener los parametros del modelo) podemos predecir nuevos valores ***y*** basandonos en valores ***x***. \n",
    "\n",
    "<div class=\"alert alert-info\">(*) Todos los valores estimados los pondremos con una caperuza (acento circunflexo, sombrero,...) para distinguirlos de valores teoricos que, en muchos casos, desconoceremos.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $a$ y $b$ son dos constantes (coeficientes o parametros del modelo lineal) que definen, respectivamente, la pendiente y el termino independiente (u ordenada en el origen o intercepto). Una vez que conocemos $\\\\hat{a}$ y $\\\\hat{b}$ (\\\\*), obtenidos a partir de los datos de entrenamiento (conjunto de datos que usamos para obtener los parametros del modelo) podemos predecir nuevos valores ***y*** basandonos en valores ***x***.\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} = \\hat{a} x + \\hat{b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para conocer $\\hat{a}$ y $\\hat{b}$ usamos los datos disponibles, como hemos comentado anteriormente. Tenemos los siguientes pares de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(x_{1}, y_{1}), (x_{2}, y_{2}), (x_{3}, y_{3}),..., (x_{n}, y_{n})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "que representan medidas de ***X*** e ***Y***. Lo que trataremos de hacer con estos datos sera obtener los parametros del ajuste lineal, $\\hat{a}$ y $\\hat{b}$, de tal forma que el modelo lineal se ajuste bien a los datos, es decir, queremos encontrar una recta con una pendiente y una ordenada en el origen que minimice la distancia a todos los puntos $(x_{i}, y_{i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varias formas de medir esta proximidad y, entre ellos, el mas usado es el ajuste por minimos cuadrados ([least squares](https://en.wikipedia.org/wiki/Least_squares))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste por minimos cuadrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El metodo de minimos cuadrados encontrara el valor optimo cuando la suma de los residuos al cuadrado, $RSS=\\sum_{i=1}^{n}{r_i}^2$ (RSS, Residual Sum of Squares), sea minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El residuo se define como la diferencia entre el valor actual de la variable dependiente y el valor predicho por el modelo, $r_{i} = y_{i} - \\hat{y}_{i}$. De esta forma tendremos lo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial{RSS}}{\\partial{\\hat{a}}} = 0 \\longrightarrow \\hat{a} = \\frac{\\sum^{n}_{i=1}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum^{n}_{i=1}(x_i - \\bar{x})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\frac{\\partial{RSS}}{\\partial{\\hat{b}}} = 0 \\longrightarrow \\hat{b} = \\bar{y} - \\hat{b}\\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $\\bar{x}$ e $\\bar{y}$ son los promedios de las muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las ecuaciones anteriores son el resultado para el caso concreto de la regresion lineal simple. Si queremos generalizar a regresion lineal multiple, mas de un termino independiente, a lo mejor lo veremos mas adelante si encuentro el tiempo necesario. Para los impacientes, si en realidad alguna vez lleguemos a verlo, puedes visitar [este enlace](https://en.wikipedia.org/wiki/Linear_least_squares_%28mathematics%29#Derivation_of_the_normal_equations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo practico del calculo de los parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos usando un conjunto de datos pequeños ([uno de los casos del cuarteto de Anscombe](http://pybonacci.org/2012/10/05/la-importancia-de-inspeccionar-los-datos/)) podemos realizar el calculo de forma manual y asi ver, paso a paso, como seria:\n",
    "\n",
    "* 1 - Calculamos el valor medio de ***X*** e ***Y***\n",
    "* 2 - Calculamos $\\hat{a}$ y $\\hat{b}$ con la ayuda de los valores medios previamente calculados\n",
    "* 3 - Comparamos el resultado con lo que obtenemos usando `numpy.polyfit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ajuste paso a paso, a, b =  0.5000909090909091 3.0000909090909103\n",
      "ajuste con polyfit, a, b =  0.5000909090909095 3.000090909090909\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "# Los datos de partida\n",
    "X = np.array([10.0, 8.0, 13.0, 9.0, 11.0, 14.0, 6.0, 4.0, 12.0, 7.0, 5.0])\n",
    "Y = np.array([8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68])\n",
    "\n",
    "# Primero calculamos la media de X e Y\n",
    "xmean = X.mean()\n",
    "ymean = Y.mean()\n",
    "\n",
    "# Como b depende de a primero hemos de obtener a\n",
    "ahat = np.sum((X - xmean) * (Y - ymean)) / np.sum((X - xmean)**2)\n",
    "bhat = ymean - ahat * xmean\n",
    "\n",
    "# Calculamos los valores usando numpy.polyfit\n",
    "a, b = np.polyfit(X, Y, 1)\n",
    "\n",
    "# Mostramos resultados\n",
    "print('ajuste paso a paso, a, b = ', ahat, bhat)\n",
    "print('ajuste con polyfit, a, b = ', a, b)\n",
    "print(np.testing.assert_almost_equal(ahat, a, decimal = 7),\n",
    "      np.testing.assert_almost_equal(bhat, b, decimal = 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver como el valor minimo para los monimos cuadrados se encuentra en ese punto si dibujamos la suma de residuos al cuadrado (RSS) en funcion de $a$ y $b$. En el siguiente grafico, si se ejecuta de forma interactiva, usando `interact`, veremos que si modificamos el valor de la pendiente y de la ordenada en el origen el valor de RSS sera superior al optimo excepto cuando $\\hat{a} = 0.5, \\hat{b} = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4b3fe55e1444fda822ea1004715126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description='ai', options=(0.3, 0.7), value=0.3), Dropdown(description='bi', options=(0.0, 6.0), value=0.0), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotea>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.linspace(0.3,0.7,100)\n",
    "b = np.linspace(0,6,100)\n",
    "RSS = np.empty((len(a), len(b)))\n",
    "for i, ai in enumerate(a):\n",
    "    for j, bj in enumerate(b):\n",
    "        RSS[i, j] = np.sum((Y - bj - ai * X)**2)\n",
    "\n",
    "def plotea(ai, bi):\n",
    "    xx, yy = np.meshgrid(b, a)    \n",
    "    levels = np.array([10,20,30,50,80,120,180,250,400,1000,2000])\n",
    "    colors = 1 - levels / levels.max()\n",
    "    plt.figure(figsize = (15,7))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(X, Y, 'o')\n",
    "    plt.plot([X.min(), X.max()], \n",
    "             [X.min() * ai + bi, X.max() * ai + bi])\n",
    "    plt.text(5, 12, 'RSS={:5.2f}'.format(np.sum((Y - bi - ai * X)**2)))\n",
    "    plt.ylim(0,14)\n",
    "    plt.subplot(122)\n",
    "    plt.contourf(yy, xx, RSS, levels = levels, colors = colors.astype('str'))\n",
    "    CS = plt.contour(yy, xx, RSS, levels = levels, colors = 'k')\n",
    "    plt.clabel(CS, inline=1, fontsize=10)\n",
    "    plt.scatter(ahat, bhat, color = 'y')\n",
    "    plt.scatter(ai, bi, color = 'g', s = 200, marker = 's')\n",
    "    plt.grid()\n",
    "\n",
    "interact(plotea, ai = [0.30, 0.70], bi = [0.0, 6.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision en la estimacipn de los parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Nuestro modelo es una aproximacion a la realidad y esta sujeto a errores. Estamos simplificando una relacion que podria no ser exactamente lineal, que podria depender de alguna otra variable que desconocemos, podria haber errores de medida en la obtencion de nuestro conjunto de datos ***X*** e ***Y***, etc. Es por ello que la relacion real la podriamos escribir como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Y = a X + b + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $\\epsilon$ es un termino de error aleatorio con media igual a cero y que consideraremos, normalmente, independiente de ***X***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo dado por la ecuacion anterior, $Y = a X + b + \\epsilon$,  es la **linea de regresion de la poblacion**, la cual, normalmente, desconoceremos. La estimacion, a partir de los datos observados, de los coeficientes de regresion de minimos cuadrados caracterizan la **linea de minimos cuadrados**. En general, en el mundo real, tenemos acceso a una serie de observaciones a partir de las cuales podemos calcular la linea de minimos cuadrados. Sin embargo, la linea de regresion de la poblacion no la podemos observar ya que nos falta parte de la informacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un hipotetico caso donde conocemos la relacion entre ***X*** e ***Y*** y que esta es $Y = 5X + 1$. Vamos a generar varios conjuntos de datos para esa relacion añadiendo el termino de error. La siguiente celda de codigo generara varios conjuntos de datos a partir de la relacion $Y = 5X + 1 + \\epsilon$. Si aumentamos el numero de lineas usadas (lineas azules) o el numero de puntos de cada conjunto veremos que, en promedio, el global (linea amarilla) se va ajustando cada vez mas a la linea de regresion de la poblacion (linea negra). Tambien observamos que el conjunto de lineas azules (lineas de minimos cuadrados para cada conjunto de datos) a veces quedan por encima y a veces quedan por debajo pero en promedio vemos que quedan cerca de la linea de regresion (linea negra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abb27d449c14a9490cc8426304eb0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='Número de líneas', min=3), IntSlider(value=5, description='Puntos para cada línea', min=5), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.genera_líneas>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def genera_líneas(numero_lineas, numero_puntos):\n",
    "    a = 5\n",
    "    b = 1\n",
    "    X = np.linspace(0, 100, int(numero_puntos))\n",
    "    Y = np.empty((len(X), int(numero_lineas) ))\n",
    "    for i in range(Y.shape[1]):\n",
    "        eps = np.random.normal(scale = 100, size = numero_puntos)\n",
    "        Y[:,i] = a * X + b + eps\n",
    "        ahat, bhat = np.polyfit(X, Y[:,i], deg = 1)\n",
    "        plt.plot(X, X * ahat + bhat, color = (0,0,0.9))\n",
    "    plt.plot(X, X * a + b, 'k', lw = 10)\n",
    "    ahat, bhat = np.polyfit(X, Y.mean(axis = 1), deg = 1)\n",
    "    plt.plot(X, X * ahat + bhat, 'y', lw = 5)\n",
    "    plt.text(20, 400, 'ahat = {:3.2f}'.format(ahat))\n",
    "    plt.text(20, 375, 'bhat = {:3.2f}'.format(bhat))\n",
    "    plt.xlim(0,100)\n",
    "    plt.ylim(-50,550)\n",
    "    \n",
    "interact(genera_líneas, \n",
    "         numero_lineas = widgets.IntSlider(min = 3, \n",
    "                                                   max = 100, \n",
    "                                                   step = 1, \n",
    "                                                   value = 3, \n",
    "                                                   description = \"Número de líneas\"), \n",
    "         numero_puntos = widgets.IntSlider(min = 5, \n",
    "                                                   max = 100, \n",
    "                                                   step = 1, \n",
    "                                                   value = 5, description=\"Puntos para cada línea\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las diferencias que vemos en el anterior grafico entre la linea negra y el resto de lineas es debido a que usamos una muestra (lineas azules) para intentar obtener caracteristicas de una poblacion mas grande (linea negra). Si la muestra de datos es mas grande o si usamos un mayor numero de lineas vemos que, en promedio (linea amarilla), nos vamos acercando cada vez mas al valor esperado. Como hemos comentado en el parrafo anterior, hay veces que las lineas pueden quedar por encima y a veces pueden quedar por debajo en mayor o menor proporcion pero, en conjunto, vemos que a medida que crece el numero de datos para cada linea o el numero de lineas, nos vamos acercando a un valor promedio. Esto nos esti indicando que en el caso de la estimacion de los parametros mediante el metodo de minimos cuadrados es no sesgada ([unbiased](https://en.wikipedia.org/wiki/Bias_of_an_estimator))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muy bien, pero normalmente solo tenemos un conjunto de datos y solo podemos hacer una estimacion con ese numero de datos. En determinados rangos podemos estar subreestimando mientras que en otros rangos podemos estar infraestimando (o viceversa). \n",
    "\n",
    "¿Como podemos estimar el error de la estimacion?\n",
    "\n",
    "Para ello podemos usar el **error estandar** ([standard error](https://en.wikipedia.org/wiki/Standard_error)) usando las siguientes formulas para el caso de una regresion lineal simple:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$SE(\\hat{a})^2 = \\frac{\\sigma^2}{\\sum_{i=1}^{n}(x_{i}-\\bar{x})^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$SE(\\hat{b})^2 = \\sigma^2[\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^{n}(x_{i}-\\bar{x})^2}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "siendo $\\sigma^2=Var(\\epsilon)$. \n",
    "\n",
    "Para que las formulas anteriores sean estrictamente validas necesitamos que los errores $\\epsilon_{i}$  para cada observacion no estan correlacionados con la varianza $\\sigma^2$. Normalmente podemos encontrar cierta correlacion pero las formulas siguen siendo una buena aproximacion.\n",
    "\n",
    "En general, $\\sigma^2$ no se conoce pero lo podemos obtener a partir de los datos. Su estimacion se conoce como error estandar residual (residual standard error) y se puede obtener a partir de $RSE (tambien\\ conocido\\ como\\ \\hat{\\sigma}) = \\sqrt{RSS / (n - 2)}$. Siendo rigurosos, cuando $\\sigma^2$ se obtiene a partir de la muestra deberiamos escribir el error estandar con una caperuza, e.g. $\\hat{SE}(\\hat{a})$, para indicar que es una estimacion. Si en algun momento se nos olvida poner la caperuza tened en cuenta que nos referimos a una estimacion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
